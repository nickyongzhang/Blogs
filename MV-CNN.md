MV-CNN for extractive document summarization
================

@author: Yong Zhang, PhD instituion: Nanyang Technological Univieristy email: <yzhang067@e.ntu.edu.sg> licence: MIT licensed. No commercial usage.

å¼•å­
----

æœ¬æ–‡ç®€å•ä»‹ç»æˆ‘å‘åœ¨IEEE Trans. on Cyberneticsä¸Šçš„ä¸€ç¯‡[è®ºæ–‡](http://ieeexplore.ieee.org/document/7756666/)ï¼Œæˆæœå·²ä¸æ˜¯æœ€æ–°ï¼Œæ–‡ç« æ˜¯2015å¹´çš„å·¥ä½œï¼ŒæŠ•ç¨¿å‘¨æœŸè¾ƒé•¿å¯¼è‡´æœ€è¿‘æ‰å‘è¡¨ã€‚æ­¤æ–‡ä¸æ˜¯æ¨ä»‹ï¼Œå®ä¹ƒå½“ä¸‹æ­£åœ¨æ‰¾å·¥ä½œï¼Œéœ€è¦å¯¹è‡ªå·±PhDæœŸé—´åšè¿‡çš„å·¥ä½œæœ‰ä¸ªæ¢³ç†ã€‚æ•…ï¼Œå†™ä¸è‡ªå·±ã€‚

ç®€ä»‹
----

å°±ç¬”è€…æ‰€çŸ¥ï¼Œæ­¤æ–‡æ˜¯ç¬¬ä¸€æ¬¡å°†multi-view learningå’ŒCNNç»“åˆåˆ°ä¸€èµ·ï¼Œæ–°çš„modelåº”ç”¨äºæŠ½å–å‹æ–‡æœ¬æ‘˜è¦ï¼Œåœ¨DUCçš„benchmark datasetä¸Šå–å¾—äº†state-of-art performanceã€‚åœ¨DUC2006æ•°æ®é›†ä¸Šï¼Œä¸literatureé‡Œæ•ˆæœæœ€å¥½çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„modelå°†Rouge-1, Rouge-2, å’ŒRouge-SU4ä¸‰ä¸ªmetricsä¸Šçš„è¡¨ç°æé«˜äº†1.28%ï¼Œ4.35%ï¼Œå’Œ3.68%ã€‚æˆ‘ä»¬å·¥ä½œçš„ä¸»è¦è´¡çŒ®å¦‚ä¸‹ï¼š

-   é¦–æ¬¡åˆ©ç”¨multi-view learningçš„complementatyå’ŒconcensusåŸåˆ™ï¼Œæé«˜CNNçš„å­¦ä¹ èƒ½åŠ›ï¼Œå®éªŒè¯æ˜multi-view learningæ˜¯CNNçš„ä¸€ä¸ªå¯è¡Œæ–¹å‘ã€‚
-   åˆ©ç”¨pre-train word embedding matrix, å®ç°æ¨¡å‹end-to-endå¯è®­ç»ƒï¼Œä¸å†éœ€è¦feature engineeringï¼Œæ¨¡å‹æ˜“äºä½¿ç”¨ã€‚
-   é¦–æ¬¡æå‡ºsentence position embeddingæŠ€æœ¯ï¼Œæé«˜æ–‡æ¡£æ‘˜è¦ä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚

ä»¥ä¸‹ï¼Œç¬”è€…å°†ä»æ–‡æ¡£æ‘˜è¦ï¼ŒCNNï¼Œword embedding, multi-view learningå‡ ä¸ªæ–¹é¢åšç®€å•ä»‹ç»ã€‚ç„¶åä»‹ç»æ–‡ç« æå‡ºçš„æ¨¡å‹ã€‚

æ–‡æ¡£æ‘˜è¦
--------

ä¿¡æ¯çˆ†ç‚¸æ—¶ä»£å¦‚ä½•å¿«é€Ÿæå–åˆ°æœ‰ç”¨ä¿¡æ¯éå¸¸é‡è¦ï¼Œæ–‡æ¡£æ‘˜è¦ä½œä¸ºä¿¡æ¯æå–é¢†åŸŸçš„é‡è¦æŠ€æœ¯ï¼Œé•¿æœŸä»¥æ¥ä¸€ç›´å¤‡å—å…³æ³¨ï¼Œè¿‘å¹´æ¥éšç€æœºå™¨å­¦ä¹ çš„ç«çƒ­ï¼Œè¶Šæ¥è¶Šå¤šçš„äººå°è¯•ç”¨æœºå™¨å­¦ä¹ æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚æ–‡æ¡£æ‘˜è¦ä¸»è¦æœ‰ä¸¤ä¸ªåˆ†æ”¯ï¼šextractive summarizationå’Œabstractive summarizationã€‚å‰è€…ç›´æ¥æå–æ–‡æ¡£æ´»æ–‡é›†é‡Œçš„å¥å­ç»„åˆæˆæœ€ç»ˆçš„æ‘˜è¦ï¼Œåè€…è¿˜éœ€è¦åšè¯­æ³•æ£€æŸ¥ï¼Œè¯­ä¹‰é‡ç»„ç­‰å¤æ‚å¤„ç†ã€‚åè€…æå–åˆ°çš„æ‘˜è¦ä¸äººå·¥æ‘˜è¦æ›´åŠ ç±»ä¼¼ï¼Œä½†æ˜¯æŠ€æœ¯æ€§å¤æ‚ï¼Œæœ¬æ–‡focusåœ¨extractive summarizationã€‚æˆ‘ä»¬é¦–å…ˆå°†æ–‡æ¡£æˆ–æ–‡é›†åˆ†å‰²æˆå¥å­ï¼Œç„¶ååˆ©ç”¨æˆ‘ä»¬çš„æ¨¡å‹å¯¹æ¯ä¸ªå¥å­å»ºæ¨¡å¹¶æ‰“åˆ†ï¼Œä¹‹åæ ¹æ®å¥å­å¾—åˆ†æ’åºï¼Œå–åˆ†æ•°å±…å‰çš„å¥å­ç»„åˆæˆæœ€ç»ˆæ‘˜è¦ã€‚æœ€åçš„æ‘˜è¦æœ‰å­—æ•°ä¸Šçº¿æˆ–è€…å¥å­æ•°ç›®ä¸Šé™ã€‚æ­¤å¤„å€¼å¾—æåˆ°çš„æ˜¯ï¼Œå¯¹äºæ–‡é›†æ‘˜è¦ä»»åŠ¡ï¼Œæ¥è‡ªä¸åŒæ–‡æ¡£çš„å¥å­å¯èƒ½ååˆ†ç›¸åŒï¼ˆä»»åŠ¡æ˜¯é’ˆå¯¹ç›¸åŒtopicçš„æ–‡æ¡£æå–æ‘˜è¦ï¼‰è€Œä¸”åŒæ—¶å¾—åˆ†å¾ˆé«˜ï¼Œæˆ‘ä»¬å°†å‰”é™¤é‡å¤æ€§å¥å­ã€‚å®Œæ•´çš„æµç¨‹å¦‚ä¸‹å›¾ï¼š ![flowchart](https://raw.githubusercontent.com/nickzylove/Blogs/master/MV-CNN_files/figure-markdown_github/framework.png)

CNN
---

Convolutional Neural Network (CNN)å¯ä»¥è¯´æ˜¯è¿‘å‡ å¹´æœ€ç«çš„ç®—æ³•ä¹‹ä¸€äº†ï¼Œå‡¡åšå›¾åƒå¿…ç”¨CNNï¼Œå› ä¸ºå…¶è‰¯å¥½çš„local representationçš„èƒ½åŠ›å¯ä»¥æœ‰æ•ˆæå–åˆ°å›¾åƒçš„å±€éƒ¨ç‰¹å¾ã€‚æœ€è¿‘CNNä¹Ÿè¢«å¹¿æ³›åº”ç”¨åˆ°NLPé¢†åŸŸï¼Œæœ¬è¯æ˜å­¦ä¹ èƒ½åŠ›ä¾ç„¶å‡ºä¼—ã€‚åŸºæœ¬çš„CNNæ¨¡å‹å¯ä»¥å‚è§Stanford CS231nè¯¾ç¨‹[CNN for visual recogonition](http://cs231n.github.io/convolutional-networks/)ã€‚æœ¬æ–‡ä½¿ç”¨çš„åŸºæœ¬CNNç»“æ„åŒ…æ‹¬ä¸¤å±‚convolution layerå’Œä¸€å±‚max pooling layerã€‚é€‰æ‹©ä¸¤å±‚convolution layerçš„åŸå› æ˜¯ç›¸è¾ƒäºä¸€å±‚å­¦ä¹ èƒ½åŠ›æœ‰è¾ƒå¤§å¹…åº¦æå‡ï¼Œè€Œå†å¢åŠ å±‚æ•°æ•ˆæœæå‡å¹¶ä¸æ˜æ˜¾å´å¯¼è‡´å¤æ‚åº¦æ€¥å‰§ä¸Šå‡ã€‚

![cnn\_arch](https://raw.githubusercontent.com/nickzylove/Blogs/master/MV-CNN_files/figure-markdown_github/cnn_structure.png)

Word Embedding
--------------

è¯å‘é‡è¿‘å¹´å‡ ä¹å·²ç»ä¸ºæ‰€æœ‰NLPä»»åŠ¡ä½¿ç”¨ï¼Œå…¶å°†æ¯ä¸ªå•è¯çš„å‘é‡è¡¨ç¤ºæ˜ å°„åˆ°ä¸€ä¸ªç›¸å¯¹ä½ç»´çš„ç©ºé—´ï¼Œå¹¶ä¸”ä¿å­˜äº†è¯è¯­çš„è¯­ä¹‰ä¿¡æ¯ã€‚ä¸‹å›¾å°†word embeddingçš„ç©ºé—´é™ç»´åˆ°2-Då¹³é¢æ–¹ä¾¿å¯è§†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°å…·æœ‰ç±»ä¼¼è¯­ä¹‰çš„è¯åœ¨word embedding spaceé‡Œè¢«èšé›†åˆ°äº†ä¸€èµ·ã€‚æ›´åŠ æœ‰åçš„æ˜¯ï¼Œword embeddingè¿˜æå–åˆ°äº†è¯ä¸è¯ç›´æ¥çš„å…³è”ï¼Œe.g., *v**e**c*(*r**a**n**c**e*)âˆ’*v**e**c*(*P**a**r**i**s*)=*v**e**c*(*C**h**i**n**a*)âˆ’*v**e**c*(*B**e**i**j**i**n**g*)ã€‚

![wordvec](https://raw.githubusercontent.com/nickzylove/Blogs/master/MV-CNN_files/figure-markdown_github/word_embedding.png)

æœ¬æ–‡ä½¿ç”¨äº†pre-trained word2vec matrixä½œä¸ºè¯å‘é‡çš„åˆå§‹åŒ–ï¼Œç„¶ååœ¨è®­ç»ƒæ¨¡å‹çš„æ—¶å€™é€šè¿‡SGDå¯¹è¯å‘é‡åšæ›´æ–°ï¼Œä»è€Œå¾—åˆ°ç‰¹å®šä»»åŠ¡ä¸‹çš„è¯å‘é‡ï¼Œå®éªŒè¯æ˜,åˆ©ç”¨åœ¨å¤§è¯­æ–™Google Newsä¸Šè®­ç»ƒçš„word embedding matrixåšåˆå§‹åŒ–å¯ä»¥æ˜¾è‘—æå‡é¢„æµ‹èƒ½åŠ›ã€‚

Multi-view Learning
-------------------

> Multiview learning is a paradigm designed for problems, where data come from diverse sources or feature subsets, also known as, multiple views. It employs one function to model a particular view and jointly optimizes all the functions to exploit the redundant views of the same input data and improve the learning performance \[1\].

Multi-view Learningä»å¤šè§’åº¦å»æå–ç›¸åŒè¾“å…¥æ•°æ®çš„ä¿¡æ¯ï¼Œè¿™ä¸€ç‚¹äººå·¥æ‘˜è¦æå–ååˆ†ç±»ä¼¼ã€‚äººå·¥æ‘˜è¦æå–çš„æ—¶å€™ï¼Œä¼šè®©å¤šä¸ªsummarizerå¯¹åŒä¸€ä¸ªæ–‡æ¡£æˆ–æ–‡é›†åšå‡ºæ€»ç»“ï¼Œæ¯ä¸ªsummarizerçš„è®¤è¯†è§’åº¦éƒ½æ˜¯ä¸åŒçš„ï¼Œæå–å‡ºæ¥çš„æœ€ç»ˆç»“æœä¹Ÿä¼šä¸å°½ç›¸åŒã€‚æˆ‘ä»¬åˆ©ç”¨multi-view learningæ¥æ¨¡ä»¿å¤šä¸ªsummarizerï¼Œåˆ©ç”¨complementary and consensusåŸåˆ™ä½¿æ–‡æœ¬ä¿¡æ¯å¾—åˆ°æœ€æœ‰æ•ˆçš„æå–å’Œè¡¨ç¤ºã€‚

Multi-view learningçš„ä¸»è¦æŠ€æœ¯åŒ…æ‹¬Co-trainingï¼ŒMultiple kernel learning algorithmsï¼Œå’ŒSubspace learning-based approachesã€‚æœ¬æ–‡ä¸­ä½¿ç”¨çš„multi-view leanringç±»ä¼¼äºMultiple kernel learningï¼ŒåŒæ—¶å…¼é¡¾co-trainingçš„å±æ€§ã€‚

Mutliview lerningæˆåŠŸçš„å…³é”®åœ¨äºä¸¤æ¡åŸåˆ™ï¼Œå³complementary and consensus principles. å‰è€…æ—¨åœ¨åˆ©ç”¨æ•°æ®éšå«çš„äº’è¡¥çš„ä¿¡æ¯ï¼Œåè€…åˆ™ç›®çš„åœ¨äºæœ€å¤§åŒ–ä¸åŒviewsä¸Šè®­ç»ƒå¾—åˆ°çš„learnersçš„ä¸€è‡´æ€§ã€‚

Methodology
-----------

æˆ‘ä»¬çš„æ–°æ¨¡å‹æˆåŠŸå°†multi-view learningå¼•å…¥ç»å…¸CNNæ¨¡å‹ï¼Œåˆ©ç”¨two-levelçš„complementary principleå’Œconsensus principleæé«˜äº†ç»å…¸CNNæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ¨¡å‹çš„æ•´ä½“æ¶æ„å¦‚ä¸‹å›¾ï¼š

![framework](https://raw.githubusercontent.com/nickzylove/Blogs/master/MV-CNN_files/figure-markdown_github/mvcnn_framework.png)

å¤šä¸ªCNNï¼ˆä¸åŒçš„filter window size, e.g., 3,5,7ï¼‰è¢«ç”¨äºæå–multiple views, æˆ‘ä»¬å°†æ¯ä¸ªCNNæå–åˆ°çš„å¥å­å‘é‡è¡¨ç¤ºç»“åˆèµ·æ¥ä½œä¸ºå¥å­çš„æœ€ç»ˆè¡¨ç¤ºï¼Œè¿™ä¸ªæ˜¯intermediate stageçš„complementary principleã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬ä¹Ÿè®©æ¯ä¸ªCNNç›´æ¥è¾“å‡ºé¢„æµ‹ç»“æœï¼Œç„¶åå°†é¢„æµ‹ç»“æœç»“åˆèµ·æ¥ä½œä¸ºfinal stageçš„complementary principleã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿè¯•å›¾æœ€å¤§åŒ–å„ä¸ªCNNçš„é¢„æµ‹ç»“æœçš„ä¸€è‡´æ€§ï¼Œä»¥æ»¡è¶³consensus principleã€‚

### Complementary Principle

æœ¬æ–‡çš„multi-view learningç±»ä¼¼äºMultiple kernel learningï¼Œæ¯ä¸€ä¸ªCNNå¯ä»¥è§†ä½œä¸€ä¸ªkernelï¼Œç”¨ä»¥æå–ä¸åŒç€çœ¼ç‚¹çš„ä¿¡æ¯ã€‚ç¬¬ä¸€å±‚complementary principleï¼Œä¹Ÿå°±æ˜¯intermediate stage complementaryå¯¹åº”ä¸Šå›¾çš„multi-view sentence representations, å¯ç±»æ¯”ä½œä¸åŒçš„sumamrizersåœ¨ç›¸äº’äº¤æ¢æ„è§ååˆä½œå¾—åˆ°ä¸€ä¸ªæ‘˜è¦ã€‚ç¬¬äºŒå±‚complementary principleï¼Œä¹Ÿå°±æ˜¯final stage complementaryå¯¹åº”ä¸Šå›¾çš„åœ†æ¡Œå›¾æ¡ˆï¼Œå¯ç±»æ¯”ä½œä¸åŒçš„summarizersåœ¨å¾—åˆ°å„è‡ªçš„æ‘˜è¦ä¹‹åç›¸äº’å¦¥åä»¥è¾¾æˆä¸€è‡´æ„è§ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„è§£é‡Šæ€§å¾ˆé«˜ï¼ŒåŒæ—¶æˆ‘ä»¬ä¹Ÿåšå‡ºäº†ä¸€äº›ç†è®ºè¯æ˜ã€‚

> Theorem 1: We denote the input as **x**, real output as *y* and the predicted output by a single CNN as *f*(**x**). The multi-view CNN predicted output is weighted sum of the distinct CNNs' outputs. Then the expected mean squared error of the a single CNN is equal or greater than that of MV-CNN.

å¦‚ä¸‹è¯æ˜è¿‡ç¨‹è¯æ˜äº†complementary principleçš„æœ‰æ•ˆæ€§

![framework](https://raw.githubusercontent.com/nickzylove/Blogs/master/MV-CNN_files/figure-markdown_github/theorem_proof.png)

### Concensus Principle

\[2\] çš„ä½œè€…è¯æ˜ä¸¤ä¸ªç‹¬ç«‹å‡è®¾çš„ä¸ä¸€è‡´æ€§æ˜¯æ¯ä¸ªå‡è®¾çš„é”™è¯¯ç‡çš„ä¸Šé™ï¼Œç”¨å…¬å¼æ¥å°†å°±æ˜¯ï¼š

*P*(*f*<sub>1</sub>â€„â‰ â€„*f*<sub>2</sub>)â‰¥*m**a**x*(*P*(*e**r**r**o**r*(*f*<sub>1</sub>)),â€†*P*(*e**r**r**o**r*(*f*<sub>2</sub>)))
 å› æ­¤æé«˜ä¸¤ä¸ªå‡è®¾ä¹‹é—´çš„ä¸€è‡´æ€§å¯ä»¥å‡å°‘å„ä¸ªå‡è®¾çš„é”™è¯¯ç‡ã€‚åº”ç”¨åˆ°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œé™ä½å„ä¸ªCNNçš„ä¸ä¸€è‡´æ€§æœ‰åˆ©äºæé«˜å„ä¸ªCNNçš„å­¦ä¹ èƒ½åŠ›ã€‚å‡è®¾å„ä¸ªCNNé¢„æµ‹çš„sentenceçš„åˆ†æ•°ä¸º*f*<sub>*i*</sub>(**x**). é‚£ä¹ˆconcensus principleå¯ä»¥è¡¨ç¤ºä¸º

*m**i**n*âˆ‘<sub>**x**</sub>âˆ‘<sub>*i*â€„â‰ â€„*j*</sub>(*f*<sub>*i*</sub>(**x**)âˆ’*f*<sub>*j*</sub>(**x**))<sup>2</sup>

### æŸå¤±å‡½æ•°

é€šå¸¸CNNæ¨¡å‹çš„æŸå¤±å‡½æ•°ä¸º

ğ•ƒâ€„=â€„âˆ’âˆ‘<sub>**x**</sub>*y**l**n*(**x**)+(1â€…âˆ’â€…*y*)*l**n*(1â€…âˆ’â€…**x**)

*y*æ˜¯æ¯ä¸ªå¥å­çš„groud-trueåˆ†æ•°ã€‚ç”±äºæˆ‘ä»¬çš„æ•°æ®åªæœ‰æ–‡æ¡£åŠå…¶å¯¹åº”çš„äººå·¥æ‘˜è¦ï¼Œå¹¶æ²¡æœ‰ç°æˆçš„å¥å­åˆ†æ•°ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚æˆ‘ä»¬å°†æ¯ä¸ªå¥å­ä¸å…¶æ‰€åœ¨æ–‡æ¡£çš„æ‘˜è¦å¯¹æ¯”ï¼Œä½¿ç”¨æ–‡æ¡£æ‘˜è¦é¢†åŸŸå¸¸ç”¨çš„performance metric, ROUGEæ¥ç»™æ¯ä¸ªå¥å­æ‰“åˆ†ã€‚ROUGEé€šè¿‡ç»Ÿè®¡äººå·¥æ‘˜è¦å’Œè‡ªåŠ¨æ‘˜è¦çš„é‡å å…ƒç´ ï¼ˆn-gram), è¯å¯¹ï¼ŒçŸ­è¯­å¯¹ç­‰çš„æ•°ç›®æ¥åˆ¤æ–­è‡ªåŠ¨æ‘˜è¦çš„ä¼˜åŠ£ã€‚æˆ‘ä»¬å–ç”¨äº†æœ€å¸¸ç”¨çš„*R**o**u**g**e*â€…âˆ’â€…1å’Œ*R**o**u**g**e*â€…âˆ’â€…2æ¥è·å¾—group-trueåˆ†æ•°ã€‚Rougeåˆ†æ•°çš„è®¡ç®—å¯ä»¥æŸ¥çœ‹æ–‡ç« ã€‚

*y*â€„=â€„*Î±**R*<sub>1</sub>(**x**)+(1â€…âˆ’â€…*Î±*)*R*<sub>2</sub>(**x**)

æˆ‘ä»¬çš„æ¨¡å‹å¼•å…¥äº†complementary and concensus principlesï¼Œæ‰€ä»¥éœ€è¦å¯¹åŸå§‹çš„æŸå¤±å‡½æ•°åšå‡ºæ”¹è¿›

ğ•ƒâ€„=â€„âˆ’âˆ‘<sub>**x**</sub>*y**l**n*(âˆ‘<sub>*i*</sub>*u*<sub>*i*</sub>*f*<sub>*i*</sub>(**x**))â€…+â€…(1â€…âˆ’â€…*y*)*l**n*(1â€…âˆ’â€…âˆ‘<sub>*i*</sub>*u*<sub>*i*</sub>*f*<sub>*i*</sub>(**x**))â€…+â€…*Î»*âˆ‘<sub>**x**</sub>âˆ‘<sub>*i*â€„â‰ â€„*j*</sub>(*f*<sub>*i*</sub>(**x**)âˆ’*f*<sub>*j*</sub>(**x**))<sup>2</sup>

### Sentence Selection

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç»™æ–‡æ¡£é‡Œçš„æ¯ä¸€ä¸ªå¥å­æ‰“åˆ†ï¼Œä»è€Œå¯¹å¥å­æ’åºã€‚å¦‚æœæ˜¯å•ä¸ªæ–‡æ¡£ï¼Œå¥å­å‡ ä¹ä¸ä¼šé‡å¤ï¼Œç›´æ¥ä½¿ç”¨åˆ†æ•°æœ€é«˜çš„å¥å­ä½œä¸ºæœ€ç»ˆçš„æ‘˜è¦æ˜¯å¯è¡Œçš„ã€‚ä½†æ˜¯å¯¹äºæ–‡é›†æ‘˜è¦ä»»åŠ¡ï¼Œæ¥è‡ªä¸åŒæ–‡æ¡£çš„å¥å­å¯èƒ½ååˆ†ç›¸åŒï¼ˆä»»åŠ¡æ˜¯é’ˆå¯¹ç›¸åŒtopicçš„æ–‡æ¡£æå–æ‘˜è¦ï¼‰ã€‚å¦‚æœé‡å¤æ€§å¥å­éƒ½å¾—åˆ°äº†è¾ƒé«˜åˆ†æ•°ï¼Œä»–ä»¬éƒ½ä¼šè¢«é€‰è¿›æœ€ç»ˆçš„æ‘˜è¦ï¼Œè¿™æ ·æ‘˜è¦çš„å¯è¯»æ€§å°±å˜å·®äº†ã€‚è€Œä¸”ç”±äºæ‘˜è¦æœ‰å­—æ•°é™åˆ¶ï¼Œä¿ç•™å†—ä½™ä¿¡æ¯ï¼Œå°±å¿…ç„¶å‡å°‘æœ‰ç”¨ä¿¡æ¯ã€‚å› æ­¤æˆ‘ä»¬å¿…é¡»å¯¹æ’åºåçš„å¥å­åŠ ä»¥é€‰æ‹©ã€‚æˆ‘ä»¬é¦–å…ˆé€‰æ‹©åˆ†æ•°æœ€é«˜çš„å¥å­æ”¾åˆ°æ‘˜è¦é‡Œï¼Œç„¶åé€‰æ‹©åˆ†æ•°å…¶æ¬¡çš„å¥å­ï¼Œæ¯”è¾ƒå®ƒå’Œå·²ç»åœ¨æ‘˜è¦é‡Œçš„å¥å­çš„ç›¸ä¼¼æ€§ï¼Œå¦‚æœç›¸ä¼¼æ€§è¿‡é«˜ï¼Œè¿™ä¸ªå¥å­å°±è¢«å‰”é™¤ã€‚å†é€‰æ‹©åˆ†æ•°å…¶æ¬¡çš„å¥å­ï¼Œå†åšæ¯”è¾ƒï¼Œä»¥æ­¤ç±»æ¨ã€‚è¿™é‡Œçš„ç›¸ä¼¼æ€§æ˜¯æ¯”è¾ƒå¥å­è¡¨ç¤ºå‘é‡çš„cosine similarityï¼Œå½“å…¶å°äºä¸€ä¸ªé˜ˆå€¼æ—¶ï¼Œæˆ‘ä»¬è®¤å®šä¸¤ä¸ªå¥å­ç±»ä¼¼ã€‚

### sentence position embedding

æœ€åè¡¥å……è¯´æ˜æˆ‘ä»¬åœ¨æ–‡ç« ä¸­å¦ä¸€åˆ›æ–°ç‚¹sentence position embeddingã€‚

å¯¹äºä¸€ä¸ªæ–‡æ¡£ï¼Œå¥å­æ‰€å¤„çš„ä½ç½®å¯¹äºä¿¡æ¯ç†è§£éå¸¸é‡è¦ã€‚ä¾‹å¦‚ï¼Œå¾ˆå¤šæƒ…å†µä¸‹ï¼Œä½œè€…å–œæ¬¢æŠŠé‡è¦ä¿¡æ¯æˆ–è€…æ¦‚æ‹¬æ€§ä¿¡æ¯æ”¾åœ¨æ–‡ç« çš„å¼€å¤´æˆ–è€…ç»“å°¾ã€‚åœ¨æ–‡æ¡£æ‘˜è¦çš„ç›¸å…³æ–‡çŒ®å½“ä¸­å°±æœ‰ä¸€ä¸ªåˆ©ç”¨å¥å­ä½ç½®ä¿¡æ¯çš„æ–¹æ³•ï¼Œå«åšLEADã€‚å®ƒä½¿ç”¨æ¯ä¸ªæ–‡ç« çš„å¼€å¤´å‡ ä¸ªå¥å­ä½œä¸ºæ–‡ç« çš„æ‘˜è¦ï¼Œä¹Ÿå–å¾—ä¸é”™æ•ˆæœã€‚ä¸ºäº†åˆ©ç”¨å¥½å¥å­çš„ä½ç½®ä¿¡æ¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†sentence position embeddingã€‚ä¸ºä»€ä¹ˆè¦å¼•å…¥sentence position embeddingï¼Ÿ

å¥å­çš„ä½ç½®ä¿¡æ¯å¯ä»¥ç”¨ç®€å•çš„è‡ªç„¶æ•°æ¥è¡¨ç¤ºï¼Œæˆ‘ä»¬åœ¨æ„çš„æ˜¯å¥å­æ‰€åœ¨å¤§æ¦‚ä½ç½®ï¼Œæ‰€ä»¥å¯ä»¥æŒ‰ç…§ä¸‹é¢çš„å…¬å¼æ¥è¡¨ç¤ºå¥å­ä½ç½®ä¿¡æ¯ã€‚*S*<sub>1â€„:â€„3</sub>è¡¨ç¤ºæ–‡ç« ä¸­çš„å‰ä¸‰å¥ï¼Œ*S*<sub>âˆ’3â€„:â€„âˆ’1</sub>è¡¨ç¤ºåä¸‰å¥ï¼Œå…¶ä»–ä½ç½®çš„å¥å­ç»Ÿä¸€ç”¨2æ¥è¡¨ç¤ºã€‚è¿™æ ·çš„è¡¨ç¤ºæ–¹æ³•æ¯”è¾ƒç²—ç³™ï¼Œä½†æ˜¯ä¹Ÿéå¸¸çš„ç®€å•ï¼Œæˆ‘ä»¬æ¨¡å‹çš„æœ€é‡è¦çš„ä¸€ä¸ªç›®çš„å°±åœ¨äºå‡å°‘äººå·¥çš„feature engineeringï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨äº†æœ€ç®€å•è€Œä¸”ç›´è§‚çš„æ–¹æ³•ã€‚

![framework](https://raw.githubusercontent.com/nickzylove/Blogs/master/MV-CNN_files/figure-markdown_github/sent_pos_embedding_equ.png)

å¥å­ä½ç½®ä¿¡æ¯å¯ä»¥ä¸CNNæå–åˆ°çš„å¥å­è¯­ä¹‰ä¿¡æ¯ç»“åˆï¼Œä¸€èµ·ä½œä¸ºé¡¶å±‚åˆ†ç±»å™¨ï¼ˆè¿™é‡Œå°±æ˜¯softmax classifier)çš„è¾“å…¥ã€‚CNNæå–åˆ°çš„å¥å­è¯­ä¹‰ä¿¡æ¯ä»¥vectorçš„å½¢å¼è¡¨ç°ï¼Œåœ¨æˆ‘ä»¬çš„modelé‡Œè¿™ä¸ªvectorçš„é•¿åº¦ä¸º300ï¼ˆåæ–‡ä¼šæœ‰æ›´å¤šè§£é‡Šï¼‰ã€‚å¦‚æœæˆ‘ä»¬åªæ˜¯ç”¨è‡ªç„¶æ•°å’Œè¿™ä¸ªè¯­ä¹‰å‘é‡è¿æ¥ï¼Œå¥å­ä½ç½®ä¿¡æ¯å¾ˆæœ‰å¯èƒ½è¢«è¯­ä¹‰å‘é‡æ‰€æ·¹æ²¡ï¼Œå› æ­¤æˆ‘ä»¬å€ŸåŠ©embeddingçš„æ€æƒ³å°†è‡ªç„¶æ•°æ˜ å°„åˆ°é«˜çº¬åº¦çš„ç©ºé—´ã€‚äº‹å®ä¸Šï¼Œword embeddingæœ¬èº«ä¹Ÿæ˜¯è®²intergerè¡¨ç¤ºæ˜ å°„ä¸ºdense vectorè¡¨ç¤ºçš„è¿‡ç¨‹ã€‚æ­¤å¤„ï¼Œæˆ‘ä»¬çš„sentence position embeddingçš„ç»´åº¦å®šä¸ºäº†100ï¼Œå¹¶ä¸”åˆå§‹åŒ–ä¸ºéšæœºçš„ï¼Œå®ƒä¹Ÿä¼šåœ¨è®­ç»ƒmodelçš„è¿‡ç¨‹ä¸­è¢«æ›´æ–°ã€‚

Experiment Results
------------------

æˆ‘ä»¬åœ¨DUCçš„äº”ä¸ªdatasetä¸Šæ£€éªŒäº†æˆ‘ä»¬modelçš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸state-of-artçš„æ–¹æ³•åšäº†å¯¹æ¯”ï¼Œç»“æœå¦‚ä¸‹å›¾ã€‚æˆ‘ä»¬åœ¨æ‰€æœ‰datasetä¸Šéƒ½å–å¾—äº†æœ€ä¼˜çš„ç»“æœ

![comparison](https://raw.githubusercontent.com/nickzylove/Blogs/master/MV-CNN_files/figure-markdown_github/experiment_result.png)

å¦å¤–æˆ‘ä»¬ä¹ŸéªŒè¯äº†complementaryå’Œconcensus principlesçš„æœ‰æ•ˆæ€§, ä»å›¾3--5ï¼Œ æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åŒæ—¶ä½¿ç”¨two-level compelmentary principleå’Œconcensus principleæœ‰åŠ©äºæé«˜å­¦ä¹ èƒ½åŠ›ã€‚å¥å­ä½ç½®ä¿¡æ¯çš„é‡è¦æ€§ç”±å›¾6ä¸­çš„ç»“æœè¯æ˜ã€‚

![principle](https://raw.githubusercontent.com/nickzylove/Blogs/master/MV-CNN_files/figure-markdown_github/experiment_result.png)

å¦‚æœå¶ç„¶é—´æœ‰è¯»è€…çœ‹åˆ°æ­¤æ–‡ï¼Œæ¬¢è¿è®¨è®ºã€‚å¦‚éœ€å¼•ç”¨ï¼Œå‚è€ƒä»¥ä¸‹ã€‚

> @ARTICLE{7756666, author={Y. Zhang and M. J. Er and R. Zhao and M. Pratama}, journal={IEEE Transactions on Cybernetics}, title={Multiview Convolutional Neural Networks for Multidocument Extractive Summarization}, year={2016}, volume={PP}, number={99}, pages={1-13}, keywords={Computational modeling;Computer vision;Data mining;Feature extraction;Machine learning;Neural networks;Semantics;Convolutional neural networks (CNNs);deep learning;multidocument summarization (MDS);multiview learning;word embedding}, doi={10.1109/TCYB.2016.2628402}, ISSN={2168-2267}, month={},}

Reference
---------

\[1\] C. Xu, D. Tao, and C. Xu, â€œA survey on multi-view learning,â€ Neural Comput. Appl., vol. 23, nos. 7â€“8, pp. 2031â€“2038, 2013. \[2\] S. Dasgupta, M. L. Littman, and D. McAllester, â€œPAC generalization bounds for co-training,â€ in Proc. Adv. Neural Inf. Process. Syst., vol. 1. Vancouver, BC, Canada, pp. 375â€“382, 2001.
